{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Step 1: Training the Models"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["total 514304\n","-rw-r--r--  1 richardjiang  staff    79M May 23 17:38 yolov10b.pt\n","-rw-r--r--  1 richardjiang  staff    11M Sep 14 23:38 yolov10n.pt\n","-rw-r--r--  1 richardjiang  staff    31M Sep 14 23:38 yolov10s.pt\n","-rw-r--r--  1 richardjiang  staff   122M May 23 17:38 yolov10x.pt\n"]}],"source":["!mkdir -p {HOME}/weights\n","!wget -P {HOME}/weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt\n","!wget -P {HOME}/weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10s.pt\n","!wget -P {HOME}/weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10b.pt\n","!wget -P {HOME}/weights -q https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10x.pt\n","!ls -lh {HOME}/weights"]},{"cell_type":"markdown","metadata":{},"source":["## 1.1 图片数据训练"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ultralytics import YOLO\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Initialize the four YOLO models\n","yolov10_models = {\n","    \"yolov10n\": YOLO(f'{HOME}/weights/yolov10n.pt'),\n","    \"yolov10s\": YOLO(f'{HOME}/weights/yolov10s.pt'),\n","    \"yolov10x\": YOLO(f'{HOME}/weights/yolov10x.pt'),\n","    \"yolov10b\": YOLO(f'{HOME}/weights/yolov10b.pt')\n","}\n","\n","# Path to the dataset configuration file (YAML)\n","DATASET_CONFIG = 'trafic_data/data_1.yaml'\n","\n","# Directory to save the training graphs for all models\n","main_folder = 'training-graphs'\n","if not os.path.exists(main_folder):  # 自动帮我们创立好文件夹\n","    os.makedirs(main_folder)  # 每个模型的文件里面总共两个图（一个accuracy，一个loss）\n","\n","# Number of epochs to wait for loss improvement before stopping\n","PATIENCE = 5\n","\n","# Train each of the four models\n","for model_name, model in yolov10_models.items():\n","    print(f\"Training {model_name}...\")\n","\n","    # Directory for saving this model's training graphs\n","    model_folder = os.path.join(main_folder, model_name)\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","    \n","    # Train the model\n","    results = model.train(\n","        data=DATASET_CONFIG,   # path to the YAML config file\n","        epochs=20,             # number of training epochs\n","        batch=128,             # batch size\n","        imgsz=640,             # image size for training (640x640)\n","        name=model_name,       # name for this experiment run\n","        workers=8,             # number of data loading workers\n","        plots=True,            # save loss and mAP plots\n","        lr0=0.001,             # learning-rate (batch size 大，lr 要小)\n","        patience=PATIENCE,     # Early stopping: stop if no improvement in 5 epochs\n","        device='0',            # 0: GPU, 1: CPU\n","        save=True,             # Checkpoints: saves the model at each improvement\n","    )\n","\n","    # Retrieve training metrics (loss, mAP, etc.)\n","    metrics = results.metrics\n","\n","    # Define the range of epochs\n","    epochs = range(1, 21)  # Adjust according to your number of epochs\n","\n","    # Loss plot\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, metrics['train/loss'], label='Training Loss')\n","    plt.plot(epochs, metrics['val/loss'], label='Validation Loss')\n","    plt.title(f'{model_name} - Loss Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    loss_file_path = os.path.join(model_folder, f'{model_name}_loss.png')\n","    plt.savefig(loss_file_path)\n","    plt.close()\n","\n","    # Accuracy (mAP) plot\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, metrics['train/map50'], label='Training mAP@0.5')\n","    plt.plot(epochs, metrics['val/map50'], label='Validation mAP@0.5')\n","    plt.title(f'{model_name} - Accuracy (mAP) Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('mAP@0.5')\n","    plt.legend()\n","    plt.grid(True)\n","    accuracy_file_path = os.path.join(model_folder, f'{model_name}_accuracy.png')\n","    plt.savefig(accuracy_file_path)\n","    plt.close()\n","\n","    print(f\"Training completed for {model_name} and plots saved in {model_folder}.\")\n","\n","print(\"All models have been trained and plots saved.\")"]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 视频类型训练数据"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["video_dataset_config = r'C:\\Users\\ASUS\\Desktop\\video_dataset_name\\name_of_the_file.yaml'\n","\n","video_training_graph_folder = \"training-graphs-video\"\n","if not os.path.exists(video_training_graph_folder):\n","    os.makedirs(video_training_graph_folder)\n","\n","for model_name, model in yolov10_models.items():\n","    print(f\"Training {model_name}...\")\n","    \n","    model_folder = os.path.join(video_training_graph_folder, model_name)\n","    if not os.path.exists(model_folder):\n","        os.makedirs(model_folder)\n","    \n","    video_train_results = model.train(\n","        data=DATASET_CONFIG,   # path to the YAML config file\n","        epochs=15,             # number of training epochs\n","        batch=128,             # batch size\n","        imgsz=640,             # image size for training (640x640)\n","        name=model_name,       # name for this experiment run\n","        workers=8,             # number of data loading workers\n","        plots=True,            # save loss and mAP plots\n","        lr0=0.001,             # learning-rate (batch size 大，lr 要小)\n","        patience=PATIENCE,     # Early stopping: stop if no improvement in 5 epochs\n","        device='0',            # 0: GPU, 1: CPU\n","        save=True,             # Checkpoints: saves the model at each improvement\n","    )\n","    epochs = range(1, 16)\n","    metrics = video_train_results.metrics\n","\n","    # Loss vs Epochs Plot\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, metrics=['train/loss'], label='Training Loss')\n","    plt.plot(epochs, metrics=['val'/'loss'], label='Validation Loss')\n","    plt.title(f'{model_name} - Loss Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylavel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    video_loss_file_path = os.path.join(model_name, f\"{model_name}_loss.png\")\n","    plt.savefig(video_loss_file_path)\n","    plt.close()\n","\n","    # Accuracy vs Epochs\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, metrics=['train'/'map50'], label='Train Accuracy')\n","    plt.plot(epochs, metrics=['val'/'map50'], label='Validation Accuracy')\n","    plt.title(f'{model_name} - Accuracy (mAP) Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy (mAP)')\n","    plt.legend()\n","    plt.grid()\n","    video_accuracy_file_path = os.path.join(model_name, f\"{model_name}_accuracy.png\")\n","    plt.savefig(video_accuracy_file_path)\n","    plt.close()\n","\n","    print(f\"Successfully complete training and validation for {model_name}\")\n","\n","print(f\"Successfully complete training and validation (video_dataset) for all models\")"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":2}
